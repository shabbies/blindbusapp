<html>
	<head>		
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
		<script src='https://cdn.firebase.com/js/client/2.2.1/firebase.js'></script>

		<style>
			#mainDiv {
    			margin-left: 35px;
    			margin-right: 35px;
    			text-align: center;
			}

			#instructionsID ul {
				display:table; 
				margin:0 auto;
			}

			#audio-player {
				opacity: 0.1; /* This is to make the audio tag transparent/invisible */
			}

			.btn-big {
				height: 1000px;
				width: 800px;
			}
		</style>
	</head>
	<!--<body onclick="trackNumClick()">-->
	<body>

		<title>Bus Selection</title>
		
		<div id="mainDiv">
			<div class="row">
				<div class="page-header col-md-12">

					<!-- <audio controls id="audio-player">
					  	<source id="audio-player-source" src="<%= asset_path('Bus_Number_English.mp3') %>" type="audio/mpeg">
					</audio> --> 

					<h1>Requesting for Bus Number</h1>
				</div>
			</div>

			<div class="row">
				<div class="col-md-12" id="instructionsID" >
					After the phone has vibrated, the user has to verbalize the bus number he/she wants to board.
				</div>
			</div>

			<br/>

			<div class="row">
				<div class="btn-group" role="group">
				  <button type="button" class="btn btn-danger col-md-12 btn-big" id="upload_voice">
				  	<font size="8">TAP HERE TO SPEAK</font></button>
				</div>
			</div>

			<div class="row">
				<div class="col-md-12">
					<%= form_tag(pages_path, :method=>'post', :multipart => true, id: "speech_form", hidden: true) do %>
				   	<%= file_field_tag "attachment", accept: 'audio/*', capture: true, id: "fileupload" %>
				   	<%= submit_tag 'Submit', hidden: true%>
					<% end %>
				</div>
			</div>


			<div class="row">
				<div class="col-md-12">
					<p class="blinking"><font color="red" size="5"><span id="listen_input"> Listening for input ... </span></font></p>
					<b><font size="6">Bus Number <br/><u><span class="tapValue"><font color="red">-</font></span></u></font></b>
				</div>
			</div>

		</div>
	</body>
</html>

<script src="https://code.responsivevoice.org/responsivevoice.js"></script>
<script>

	var leftchannel = [];
	var rightchannel = [];
	var recorder = null;
	var recording = false;
	var recordingLength = 0;
	var volume = null;
	var audioInput = null;
	var sampleRate = null;
	var audioContext = null;
	var context = null;
	var outputElement = document.getElementById('output');
	var outputString;

	// enable vibration support
	navigator.vibrate = navigator.vibrate || navigator.webkitVibrate || navigator.mozVibrate || navigator.msVibrate;

	$(document).ready(function () {
		
		// setting audio recording parameters
	  navigator.getUserMedia =
	  navigator.getUserMedia ||
	  navigator.webkitGetUserMedia ||
	  navigator.mozGetUserMedia ||
	  navigator.msGetUserMedia;

		navigator.getUserMedia({audio:true}, success, function(e) {
		    alert('Error capturing video.');
		});


    setTimeout(function(){
    	responsiveVoice.speak("Please say the bus number you wish to board after the phone has vibrated.");
      //after responsive voice, then vibrate
      setTimeout(function(){
      	if (navigator.vibrate) {
	          navigator.vibrate(1000);
	          recording = true;
			      // reset the buffers for the new recording
			      leftchannel.length = rightchannel.length = 0;
			      recordingLength = 0;
	      } //end navigator vibrate
      }, 5000)
    }, 2000);

    setTimeout(function(){
  		// we stop recording
      recording = false;

      // we flat the left and right channels down
      var leftBuffer = mergeBuffers ( leftchannel, recordingLength );
      var rightBuffer = mergeBuffers ( rightchannel, recordingLength );
      // we interleave both channels together
      var interleaved = interleave ( leftBuffer, rightBuffer );
      
      // we create our wav file
      var buffer = new ArrayBuffer(44 + interleaved.length * 2);
      var view = new DataView(buffer);
      
      // RIFF chunk descriptor
      writeUTFBytes(view, 0, 'RIFF');
      view.setUint32(4, 44 + interleaved.length * 2, true);
      writeUTFBytes(view, 8, 'WAVE');
      // FMT sub-chunk
      writeUTFBytes(view, 12, 'fmt ');
      view.setUint32(16, 16, true);
      view.setUint16(20, 1, true);
      // stereo (2 channels)
      view.setUint16(22, 2, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, sampleRate * 4, true);
      view.setUint16(32, 4, true);
      view.setUint16(34, 16, true);
      // data sub-chunk
      writeUTFBytes(view, 36, 'data');
      view.setUint32(40, interleaved.length * 2, true);
      
      // write the PCM samples
      var lng = interleaved.length;
      var index = 44;
      var volume = 1;
      for (var i = 0; i < lng; i++){
          view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);
          index += 2;
      }
      
      // our final binary blob
      var blob = new Blob ( [ view ], { type : 'audio/wav' } );
      
      // let's save it locally
      // var url = (window.URL || window.webkitURL).createObjectURL(blob);
      // var link = window.document.createElement('a');
      // link.href = url;
      // link.download = 'output.wav';
      // var click = document.createEvent("Event");
      // click.initEvent("click", true, true);
      // link.dispatchEvent(click);

      var form = new FormData(),
			    request = new XMLHttpRequest();
			form.append("attachment",blob);
			request.onreadystatechange = function() {
			  if (request.readyState == 4 && request.status == 200) {
			    window.location.replace("<%= number_pages_path %>");
			  }
			}
			request.open(
			            "POST",
			            "<%=pages_path%>",
			            true
			        );
			request.send(form);
    }, 10000);

		$('#listen_input').hide(); //this will only show when system is ready to listen for input

		/*
		//this will return selected_language=English/Mandarin 
		url_params = window.location.search.substr(1).split('=');
		selected_language = url_params[2];

		if (selected_language == "Mandarin"){
			$("#audio-player-source").attr("src", "<%= asset_path('Bus_Number_Mandarin.mp3') %>");
		} */


    

		function blinker() {
			$('.blinking').fadeOut(300);
			$('.blinking').fadeIn(300);
		}
		setInterval(blinker, 1000);

		/*
		$('#start_btn').click(function() {
			var audioPlayer = document.getElementById('audio-player');
	    	audioPlayer.play();
	    	$('#start_btn').hide();
	    	//$('#listen_input').show();
		}); */

		$("#upload_voice").click(function() {
			$("#fileupload").click();
		});

		$("#fileupload").change(function(){
			$("#speech_form").submit();
		});	




	});
</script>

<script>
	function interleave(leftChannel, rightChannel){
	  var length = leftChannel.length + rightChannel.length;
	  var result = new Float32Array(length);

	  var inputIndex = 0;

	  for (var index = 0; index < length; ){
	    result[index++] = leftChannel[inputIndex];
	    result[index++] = rightChannel[inputIndex];
	    inputIndex++;
	  }
	  return result;
	}

	function mergeBuffers(channelBuffer, recordingLength){
	  var result = new Float32Array(recordingLength);
	  var offset = 0;
	  var lng = channelBuffer.length;
	  for (var i = 0; i < lng; i++){
	    var buffer = channelBuffer[i];
	    result.set(buffer, offset);
	    offset += buffer.length;
	  }
	  return result;
	}

	function writeUTFBytes(view, offset, string){ 
	  var lng = string.length;
	  for (var i = 0; i < lng; i++){
	    view.setUint8(offset + i, string.charCodeAt(i));
	  }
	}

	function success(e){
	    // creates the audio context
	    audioContext = window.AudioContext || window.webkitAudioContext;
	    context = new audioContext();

		// we query the context sample rate (varies depending on platforms)
	    sampleRate = context.sampleRate;

	    console.log('succcess');
	    
	    // creates a gain node
	    volume = context.createGain();

	    // creates an audio node from the microphone incoming stream
	    audioInput = context.createMediaStreamSource(e);

	    // connect the stream to the gain node
	    audioInput.connect(volume);

	    /* From the spec: This value controls how frequently the audioprocess event is 
	    dispatched and how many sample-frames need to be processed each call. 
	    Lower values for buffer size will result in a lower (better) latency. 
	    Higher values will be necessary to avoid audio breakup and glitches */
	    var bufferSize = 2048;
	    recorder = context.createScriptProcessor(bufferSize, 2, 2);

	    recorder.onaudioprocess = function(e){
	        if (!recording) return;
	        var left = e.inputBuffer.getChannelData (0);
	        var right = e.inputBuffer.getChannelData (1);
	        // we clone the samples
	        leftchannel.push (new Float32Array (left));
	        rightchannel.push (new Float32Array (right));
	        recordingLength += bufferSize;
	        console.log('recording');
	    }

	    // we connect the recorder
	    volume.connect (recorder);
	    recorder.connect (context.destination); 
	}
</script>